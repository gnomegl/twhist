#!/usr/bin/env bash

USERNAME=""
OUTPUT="pretty"
LIMIT="0"
SORT="count"
REVERSE=0
FILTER=""
MIN_COUNT="1"
SHOW_URLS=0
SHOW_DATES=0
QUIET=0
VERBOSE=0

show_usage() {
  cat <<'EOF'
Twitter/X username OSINT tool using CDX

USAGE:
    twitter-osint.sh <username> [OPTIONS]

ARGUMENTS:
    <username>          Twitter username to search for (without @)

OPTIONS:
    -o, --output FORMAT     Output format (pretty, raw, json) [default: pretty]
    -l, --limit NUMBER      Limit number of results (0 for no limit) [default: 0]
    -s, --sort FIELD        Sort results by (username, count, first_seen, last_seen) [default: count]
    -r, --reverse           Reverse sort order
    -f, --filter STRING     Filter usernames containing this string
    -m, --min-count NUMBER  Minimum tweet count to include [default: 1]
    --show-urls             Show sample URLs for each username
    --show-dates            Show first/last seen dates
    -q, --quiet             Suppress colored output and progress indicators
    -h, --help              Show this help message

EXAMPLES:
    twitter-osint.sh elonmusk
    twitter-osint.sh twitter --output json --limit 10
    twitter-osint.sh example --sort count --reverse --min-count 5
    twitter-osint.sh user --filter "bot" --show-urls

REQUIRED TOOLS:
    curl, awk, sed, sort, uniq, date
EOF
}

# Parse command line arguments
parse_args() {
  while [[ $# -gt 0 ]]; do
    case $1 in
    -h | --help)
      show_usage
      exit 0
      ;;
    -o | --output)
      OUTPUT="$2"
      shift 2
      ;;
    -l | --limit)
      LIMIT="$2"
      shift 2
      ;;
    -s | --sort)
      SORT="$2"
      shift 2
      ;;
    -r | --reverse)
      REVERSE=1
      shift
      ;;
    -f | --filter)
      FILTER="$2"
      shift 2
      ;;
    -m | --min-count)
      MIN_COUNT="$2"
      shift 2
      ;;
    --show-urls)
      SHOW_URLS=1
      shift
      ;;
    --show-dates)
      SHOW_DATES=1
      shift
      ;;
    -q | --quiet)
      QUIET=1
      shift
      ;;
    -v | --verbose)
      VERBOSE=1
      shift
      ;;
    -*)
      echo "Error: Unknown option $1" >&2
      show_usage >&2
      exit 1
      ;;
    *)
      if [ -z "$USERNAME" ]; then
        USERNAME="$1"
      else
        echo "Error: Multiple usernames provided. Only one username is allowed." >&2
        exit 1
      fi
      shift
      ;;
    esac
  done

  # Check if username was provided
  if [ -z "$USERNAME" ]; then
    echo "Error: Username is required" >&2
    show_usage >&2
    exit 1
  fi

  # Validate output format
  case "$OUTPUT" in
  pretty | raw | json) ;;
  *)
    echo "Error: Invalid output format '$OUTPUT'. Use: pretty, raw, or json" >&2
    exit 1
    ;;
  esac

  # Validate sort field
  case "$SORT" in
  username | count | first_seen | last_seen) ;;
  *)
    echo "Error: Invalid sort field '$SORT'. Use: username, count, first_seen, or last_seen" >&2
    exit 1
    ;;
  esac

  # Validate numeric arguments
  if ! [[ "$LIMIT" =~ ^[0-9]+$ ]]; then
    echo "Error: Invalid limit '$LIMIT'. Must be a number." >&2
    exit 1
  fi

  if ! [[ "$MIN_COUNT" =~ ^[0-9]+$ ]]; then
    echo "Error: Invalid min-count '$MIN_COUNT'. Must be a number." >&2
    exit 1
  fi
}

setup_colors() {
  if [ "$QUIET" = 1 ] || [ -z "$TERM" ] || [ "$TERM" = "dumb" ]; then
    bold="" reset="" blue="" green="" yellow="" cyan="" magenta="" red="" gray=""
  else
    bold=$(tput bold) reset=$(tput sgr0) blue=$(tput setaf 4) green=$(tput setaf 2)
    yellow=$(tput setaf 3) cyan=$(tput setaf 6) magenta=$(tput setaf 5) red=$(tput setaf 1)
    gray=$(tput setaf 8)
  fi
}

show_progress() {
  if [ "$QUIET" != 1 ]; then
    printf "${gray}%s${reset}\n" "$1" >&2
  fi
}

error_exit() {
  printf "${red}Error:${reset} %s\n" "$1" >&2
  exit 1
}

validate_username() {
  local username="$1"
  username="${username#@}"

  if [[ ! "$username" =~ ^[a-zA-Z0-9_]+$ ]]; then
    error_exit "Invalid Twitter username format: $username"
  fi

  echo "$username"
}

timestamp_to_date() {
  local timestamp="$1"
  if [ ${#timestamp} -eq 14 ]; then
    local year="${timestamp:0:4}"
    local month="${timestamp:4:2}"
    local day="${timestamp:6:2}"
    echo "${year}-${month}-${day}"
  else
    echo "Unknown"
  fi
}

fetch_cdx_data() {
  local username="$1"
  local url="http://web.archive.org/cdx/search/cdx?url=twitter.com/${username}*&output=text&fl=timestamp,original&collapse=urlkey"

  show_progress "Searching for username: ${username}"

  local response=$(curl -s "$url" 2>/dev/null)
  local curl_exit=$?

  if [ $curl_exit -ne 0 ]; then
    error_exit "Failed to fetch data from CDX (curl exit code: $curl_exit)"
  fi

  if [ -z "$response" ]; then
    show_progress "No data found for username: ${username}"
    return 1
  fi

  echo "$response"
}

fetch_oembed_data() {
  local tweet_url="$1"
  local oembed_url="https://publish.twitter.com/oembed?url=${tweet_url}"

  local response=$(curl -s "$oembed_url" 2>/dev/null)

  # Check if response contains actual oEmbed data
  if echo "$response" | grep -q '"author_name"'; then
    echo "$response"
  else
    echo ""
  fi
}

process_cdx_data() {
  local cdx_data="$1"
  local temp_file=$(mktemp)
  local processed_file=$(mktemp)
  local raw_data_file=$(mktemp)
  local oembed_file=$(mktemp)
  local username_changes_file=$(mktemp)

  # Write CDX data to a temporary file to avoid pipe issues
  echo "$cdx_data" >"$raw_data_file"

  # Count the total number of lines for progress reporting
  local total_lines=$(wc -l <"$raw_data_file")
  show_progress "Processing $total_lines records..."

  # Use a timeout to prevent hanging
  local timeout_seconds=300 # 5 minutes timeout
  local start_time=$(date +%s)
  local line_count=0
  local progress_interval=$((total_lines > 100 ? total_lines / 10 : 10))

  # Process the data line by line from the file instead of using a pipe
  while IFS=' ' read -r timestamp original_url; do
    [ -z "$timestamp" ] || [ -z "$original_url" ] && continue

    # Check for timeout
    local current_time=$(date +%s)
    local elapsed_time=$((current_time - start_time))
    if [ $elapsed_time -gt $timeout_seconds ]; then
      show_progress "Processing timed out after ${timeout_seconds} seconds. Processing partial results..."
      break
    fi

    line_count=$((line_count + 1))

    # Show progress every 10% or 10 lines
    if [ $((line_count % progress_interval)) -eq 0 ]; then
      show_progress "Processed $line_count of $total_lines records ($((line_count * 100 / total_lines))%)..."
    fi

    local extracted_username=$(echo "$original_url" | sed 's|https://twitter.com/||' | cut -d'/' -f1 | cut -d'?' -f1)

    [ -z "$extracted_username" ] && continue

    # Skip invalid usernames like "http:"
    [[ "$extracted_username" == "http:" ]] && continue
    [[ ! "$extracted_username" =~ ^[a-zA-Z0-9_]+$ ]] && continue

    if [ -n "$FILTER" ]; then
      if [[ ! "$extracted_username" == *"$FILTER"* ]]; then
        continue
      fi
    fi

    echo "$timestamp|$extracted_username|$original_url" >>"$temp_file"
  done <"$raw_data_file"

  # Check if we processed any data
  if [ ! -s "$temp_file" ]; then
    show_progress "No usernames found in the processed data."
    rm -f "$temp_file" "$processed_file" "$raw_data_file" "$oembed_file" "$username_changes_file"
    return 1
  fi

  # Collect oEmbed data for a sample of tweets per username
  show_progress "Analyzing data for username verification..."

  # Get unique usernames and their sample URLs (limit to 10 for performance)
  local oembed_count=0
  local max_oembed_checks=5000
  local checked_usernames=""

  awk -F'|' '{print $2 "|" $3}' "$temp_file" | sort -u | while IFS='|' read -r username url; do
    # Skip if we already checked this username
    if [[ "$checked_usernames" == *"|$username|"* ]]; then
      continue
    fi

    # Limit oEmbed checks for performance
    if [ $oembed_count -ge $max_oembed_checks ]; then
      break
    fi

    # Only fetch oEmbed for status URLs
    if [[ "$url" =~ /status/[0-9]+ ]]; then
      local oembed_data=$(fetch_oembed_data "$url")
      if [ -n "$oembed_data" ]; then
        oembed_count=$((oembed_count + 1))
        checked_usernames="${checked_usernames}|${username}|"

        local author_name=$(echo "$oembed_data" | sed -n 's/.*"author_name":"\([^"]*\)".*/\1/p')
        local author_url=$(echo "$oembed_data" | sed -n 's/.*"author_url":"\([^"]*\)".*/\1/p' | sed 's/\\//g')
        local url_username=$(echo "$author_url" | sed 's|https://twitter.com/||' | sed 's|/.*||')

        if [ -n "$author_name" ] && [ -n "$url_username" ]; then
          if [[ ! "$author_name" =~ (404|[Pp]age.not.found|[Ee]rror|[Nn]ot.[Ff]ound) ]]; then
            echo "$username|$url_username|$author_name|$url" >>"$oembed_file"
          else
            echo "$username|$url_username||$url" >>"$oembed_file"
          fi

          if [ "$username" != "$url_username" ]; then
            if ! grep -q "^$username → " "$username_changes_file" 2>/dev/null; then
              # Only include display name if it doesn't contain error indicators
              if [[ ! "$author_name" =~ (404|[Pp]age.not.found|[Ee]rror|[Nn]ot.[Ff]ound) ]]; then
                echo "$username → $url_username (display: $author_name)" >>"$username_changes_file"
              else
                echo "$username → $url_username" >>"$username_changes_file"
              fi
            fi
          fi
        fi
      fi
    fi
  done

  # Load oEmbed data into memory for enrichment
  declare -A oembed_names
  declare -A oembed_usernames
  declare -A username_changes

  if [ -s "$oembed_file" ]; then
    while IFS='|' read -r orig_user current_user display_name url; do
      oembed_names["$orig_user"]="$display_name"
      oembed_usernames["$orig_user"]="$current_user"
      if [ "$orig_user" != "$current_user" ]; then
        username_changes["$orig_user"]="$current_user"
      fi
    done <"$oembed_file"

    # Debug: show loaded data
    # show_progress "Loaded ${#oembed_names[@]} oEmbed entries"
  fi

  awk -F'|' '
    {
        timestamp = $1
        username = $2
        url = $3

        count[username]++

        if (username in first_seen) {
            if (timestamp < first_seen[username]) {
                first_seen[username] = timestamp
            }
        } else {
            first_seen[username] = timestamp
        }

        if (username in last_seen) {
            if (timestamp > last_seen[username]) {
                last_seen[username] = timestamp
            }
        } else {
            last_seen[username] = timestamp
        }

        if (sample_url[username] == "") {
            sample_url[username] = url
        }
    }
    END {
        for (u in count) {
            if (count[u] >= '"${MIN_COUNT}"') {
                print u "|" count[u] "|" first_seen[u] "|" last_seen[u] "|" sample_url[u]
            }
        }
    }' "$temp_file" >"$processed_file"

  local sort_field=""
  case "$SORT" in
  "username") sort_field="-k1,1" ;;
  "count") sort_field="-k2,2n" ;;
  "first_seen") sort_field="-k3,3" ;;
  "last_seen") sort_field="-k4,4" ;;
  *) sort_field="-k2,2n" ;;
  esac

  if [ "$REVERSE" = 1 ]; then
    sort_field="${sort_field}r"
  fi

  # Enrich the sorted data with oEmbed information
  local enriched_file=$(mktemp)

  while IFS='|' read -r username count first last url; do
    local display_name="${oembed_names[$username]:-}"
    local current_username="${oembed_usernames[$username]:-}"
    local changed_to="${username_changes[$username]:-}"

    echo "$username|$count|$first|$last|$url|$display_name|$current_username|$changed_to"
  done < <(sort -t'|' $sort_field "$processed_file") >"$enriched_file"

  cat "$enriched_file"

  # Output username changes summary if any were found
  if [ -s "$username_changes_file" ] && [ "$VERBOSE" = 1 ]; then
    echo "=USERNAME_CHANGES="
    cat "$username_changes_file"
    echo "=END_USERNAME_CHANGES="
  fi

  rm -f "$temp_file" "$processed_file" "$raw_data_file" "$oembed_file" "$username_changes_file" "$enriched_file"
}

output_raw() {
  local processed_data="$1"
  local count=0
  local temp_file=$(mktemp)

  # Write processed data to a temporary file to avoid pipe issues
  echo "$processed_data" >"$temp_file"

  # Skip username changes section if present
  grep -v "^=USERNAME_CHANGES=" "$temp_file" | grep -v "^=END_USERNAME_CHANGES=" |
    while IFS='|' read -r username tweet_count first_seen last_seen sample_url display_name current_username changed_to; do
      [ -z "$username" ] && continue

      if [ "$LIMIT" -gt 0 ] && [ $count -ge "$LIMIT" ]; then
        break
      fi

      echo "$username"
      count=$((count + 1))
    done

  rm -f "$temp_file"
}

output_json() {
  local processed_data="$1"
  local count=0
  local first=1
  local temp_file=$(mktemp)

  # Write processed data to a temporary file to avoid pipe issues
  echo "$processed_data" >"$temp_file"

  echo "["

  # Skip username changes section if present
  grep -v "^=USERNAME_CHANGES=" "$temp_file" | grep -v "^=END_USERNAME_CHANGES=" |
    while IFS='|' read -r username tweet_count first_seen last_seen sample_url display_name current_username changed_to; do
      [ -z "$username" ] && continue

      if [ "$LIMIT" -gt 0 ] && [ $count -ge "$LIMIT" ]; then
        break
      fi

      if [ $first -eq 1 ]; then
        first=0
      else
        echo ","
      fi

      local first_date=$(timestamp_to_date "$first_seen")
      local last_date=$(timestamp_to_date "$last_seen")

      printf '  {\n'
      printf '    "username": "%s",\n' "$username"
      printf '    "tweet_count": %s,\n' "$tweet_count"
      printf '    "first_seen": "%s",\n' "$first_date"
      printf '    "last_seen": "%s",\n' "$last_date"
      printf '    "sample_url": "%s"' "$sample_url"

      # Add oEmbed data if available
      if [ -n "$display_name" ] || [ -n "$current_username" ] || [ -n "$changed_to" ]; then
        printf ',\n    "oembed_data": {\n'
        [ -n "$display_name" ] && printf '      "display_name": "%s",\n' "$display_name"
        [ -n "$current_username" ] && printf '      "current_username": "%s",\n' "$current_username"
        [ -n "$changed_to" ] && printf '      "username_changed_to": "%s",\n' "$changed_to"
        # Remove trailing comma
        printf '\b \b'
        printf '\n    }'
      fi

      printf '\n  }'

      count=$((count + 1))
    done

  rm -f "$temp_file"
  echo ""
  echo "]"
}

output_pretty() {
  local processed_data="$1"
  local temp_file=$(mktemp)
  local changes_file=$(mktemp)

  # Write processed data to a temporary file to avoid pipe issues
  echo "$processed_data" >"$temp_file"

  # Extract username changes if present
  local has_changes=0
  if grep -q "^=USERNAME_CHANGES=" "$temp_file"; then
    has_changes=1
    sed -n '/^=USERNAME_CHANGES=/,/^=END_USERNAME_CHANGES=/p' "$temp_file" |
      grep -v "^=USERNAME_CHANGES=" | grep -v "^=END_USERNAME_CHANGES=" >"$changes_file"
  fi

  # Count usernames and tweets from the main data
  local total_usernames=$(grep -v "^=USERNAME_CHANGES=" "$temp_file" | grep -v "^=END_USERNAME_CHANGES=" | grep -v "^$" | wc -l)
  local total_tweets=0
  local count=0

  grep -v "^=USERNAME_CHANGES=" "$temp_file" | grep -v "^=END_USERNAME_CHANGES=" |
    while IFS='|' read -r username tweet_count first_seen last_seen sample_url display_name current_username changed_to; do
      [ -z "$username" ] && continue
      total_tweets=$((total_tweets + tweet_count))
    done

  printf "${bold}${green}Twitter Username OSINT Results${reset}\n"
  printf "${bold}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${reset}\n\n"

  # printf "${bold}Summary:${reset}\n"
  # printf "  ${cyan}Total Usernames Found:${reset} ${yellow}%s${reset}\n" "$total_usernames"
  # printf "  ${cyan}Total Archived Tweets:${reset} ${yellow}%s${reset}\n" "$total_tweets"
  # printf "  ${cyan}Minimum Tweet Count:${reset} ${yellow}%s${reset}\n" "$MIN_COUNT"
  # if [ -n "$FILTER" ]; then
  #   printf "  ${cyan}Filter Applied:${reset} ${yellow}%s${reset}\n" "$FILTER"
  # fi
  # printf "  ${cyan}Sort Order:${reset} ${yellow}%s${reset}" "$SORT"
  # [ "$REVERSE" = 1 ] && printf " ${gray}(reversed)${reset}"
  # printf "\n\n"

  printf "${bold}Results:${reset}\n"
  printf "${bold}%-40s %8s %12s %12s${reset}" "Username" "Tweets" "First Seen" "Last Seen"
  if [ "$SHOW_URLS" = 1 ] || [ "$VERBOSE" = 1 ]; then
    printf " %s" "Sample URL"
  fi
  printf "\n"
  printf "${gray}%-40s %8s %12s %12s" "--------" "------" "-----------" "----------"
  if [ "$SHOW_URLS" = 1 ] || [ "$VERBOSE" = 1 ]; then
    printf " %s" "----------"
  fi
  printf "${reset}\n"

  grep -v "^=USERNAME_CHANGES=" "$temp_file" | grep -v "^=END_USERNAME_CHANGES=" |
    while IFS='|' read -r username tweet_count first_seen last_seen sample_url display_name current_username changed_to; do
      [ -z "$username" ] && continue

      if [ "$LIMIT" -gt 0 ] && [ $count -ge "$LIMIT" ]; then
        break
      fi

      local first_date=$(timestamp_to_date "$first_seen")
      local last_date=$(timestamp_to_date "$last_seen")

      local count_color="$reset"
      if [ "${tweet_count:-0}" -gt 100 ]; then
        count_color="$green"
      elif [ "${tweet_count:-0}" -gt 10 ]; then
        count_color="$yellow"
      else
        count_color="$red"
      fi

      # Format username with display name if available
      local username_display="$username"
      if [ -n "$display_name" ]; then
        # Truncate display name if too long
        local max_display_len=25
        local truncated_display="$display_name"
        if [ ${#display_name} -gt $max_display_len ]; then
          truncated_display="${display_name:0:$max_display_len}..."
        fi
        username_display="$username ($truncated_display)"
      fi

      printf "${blue}%-40s${reset} ${count_color}%8s${reset} ${magenta}%12s${reset} ${magenta}%12s${reset}" \
        "$username_display" "$tweet_count" "$first_date" "$last_date"

      if [ "$SHOW_URLS" = 1 ] || [ "$VERBOSE" = 1 ]; then
        printf " ${gray}%s${reset}" "$sample_url"
      fi
      printf "\n"

      # Show oEmbed data if available (skip display name since it's shown inline)
      if ([ -n "$current_username" ] || [ -n "$changed_to" ]); then
        if [ -n "$current_username" ] && [ "$current_username" != "$username" ]; then
          printf "  ${gray}├─ Current Username: ${cyan}@%s${reset}\n" "$current_username"
        fi
        if [ -n "$changed_to" ]; then
          printf "  ${gray}└─ Username Changed To: ${red}@%s${reset}\n" "$changed_to"
        fi
      # elif [ -n "$changed_to" ]; then
      #   printf "  ${red}→ @%s${reset}\n" "$changed_to"
      fi

      if [ "$SHOW_DATES" = 1 ] && [ "$SHOW_URLS" != 1 ] && [ "$VERBOSE" != 1 ]; then
        printf "  ${gray}First: %s, Last: %s${reset}\n" "$first_date" "$last_date"
      fi

      count=$((count + 1))
    done

  # Show username changes summary if in verbose mode
  if [ "$has_changes" = 1 ] && [ "$VERBOSE" = 1 ] && [ -s "$changes_file" ]; then
    printf "\n${bold}${yellow}Username Changes Detected:${reset}\n"
    printf "${gray}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${reset}\n"
    while IFS= read -r change; do
      printf "${red}%s${reset}\n" "$change"
    done <"$changes_file"
  fi

  rm -f "$temp_file" "$changes_file"

  if [ "$LIMIT" -gt 0 ] && [ "$total_usernames" -gt "$LIMIT" ]; then
    printf "\n${gray}Showing %s of %s results (use --limit 0 to show all)${reset}\n" "$LIMIT" "$total_usernames"
  fi
}

main() {
  parse_args "$@"
  setup_colors

  local username=$(validate_username "$USERNAME")
  local cdx_data=$(fetch_cdx_data "$username")

  if [ -z "$cdx_data" ]; then
    if [ "$OUTPUT" = "json" ]; then
      echo "[]"
    else
      show_progress "No usernames found for: ${username}"
    fi
    exit 0
  fi

  local processed_data=$(process_cdx_data "$cdx_data")

  if [ -z "$processed_data" ]; then
    if [ "$OUTPUT" = "json" ]; then
      echo "[]"
    else
      show_progress "No usernames found matching criteria"
    fi
    exit 0
  fi

  case "$OUTPUT" in
  "raw")
    output_raw "$processed_data"
    ;;
  "json")
    output_json "$processed_data"
    ;;
  "pretty" | *)
    output_pretty "$processed_data"
    ;;
  esac
}

main "$@"
